{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiP/U81vqvMBl4Nm2KIoSU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roberthouston14/GNN-Class/blob/main/Spam_Dataset_Aggregator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FANJ4cvRISv"
      },
      "outputs": [],
      "source": [
        "# This code reads the Enron Email Dataset, the SpamAssassin Public Corpus, \n",
        "# and the Ling-Spam Dataset from their respective URLs, and concatenates them \n",
        "# into a single DataFrame. Note that the Ling-Spam Dataset uses a different label \n",
        "# convention (\"spam\" and \"ham\"), so we map the labels to the same convention \n",
        "# as the other datasets. You can adjust the code to include other datasets, \n",
        "# as long as they are in a compatible format and have the necessary annotations.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# read Enron Email Dataset from URL\n",
        "enron_url = 'https://raw.githubusercontent.com/ahmedbesbes/emails-classification/master/dataset/emails.csv'\n",
        "enron_df = pd.read_csv(enron_url)\n",
        "enron_df = enron_df[['text', 'spam']]\n",
        "enron_df = enron_df.rename(columns={'text': 'Text', 'spam': 'target'})\n",
        "enron_df['target'] = enron_df['target'].map({1: 1, 0: 0})\n",
        "\n",
        "# read SpamAssassin Public Corpus from URL\n",
        "sa_url = 'https://raw.githubusercontent.com/ctuning/ck-mlops/master/module/ai-object-detection/dataset/dataset_spamAssassinPublicCorpus.csv'\n",
        "sa_df = pd.read_csv(sa_url)\n",
        "sa_df = sa_df[['text', 'spam']]\n",
        "sa_df = sa_df.rename(columns={'text': 'Text', 'spam': 'target'})\n",
        "sa_df['target'] = sa_df['target'].map({1: 1, 0: 0})\n",
        "\n",
        "# read Ling-Spam Dataset from URL\n",
        "ling_url = 'https://raw.githubusercontent.com/brian-arr/ling-spam/master/ling-spam.csv'\n",
        "ling_df = pd.read_csv(ling_url, encoding='latin-1')\n",
        "ling_df = ling_df[['text', 'class']]\n",
        "ling_df = ling_df.rename(columns={'text': 'Text', 'class': 'target'})\n",
        "ling_df['target'] = ling_df['target'].map({'spam': 1, 'ham': 0})\n",
        "\n",
        "# concatenate the datasets\n",
        "combined_df = pd.concat([enron_df, sa_df, ling_df], ignore_index=True)\n",
        "\n",
        "# save the combined dataset to a CSV file\n",
        "combined_df.to_csv('combined_dataset.csv', index=False)\n"
      ]
    }
  ]
}